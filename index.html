<!DOCTYPE html>
<html>
<meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="js/bootstrap.js"></script>
    <script src="js/ga.js"></script>
    <link rel="stylesheet" href="stylesheet.css">
    <title>Home</title>
  </head>
  <body>
    <div class="container">
      <nav class="navbar navbar-default">
        <div class="container-fluid">
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="nav-dark nav navbar-nav">
                <li><a href="index.html">Home </a></li>
                <li><a href="#media">Media </a></li>
                <li><a href="#research">Research </a></li>
                <li><a href="#papers">Papers </a></li>
                <li><a href="#talks">Talks </a></li>
                <li><a href="#students">Students </a></li>
                <li><a href="#service">Service </a></li>
            </ul>
          </div>
        </div>
      </nav>
    </div>
  <link rel="stylesheet" href="bootstrap.css">
  </body>
</html>


<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-174836114-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-174836114-1');
    </script>

    <title>Khimya Khetarpal</title>

    <meta name="author" content="Khimya Khetarpal">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Khimya Khetarpal</name>
              </p>

              <p> I am a Research Scientist at <a href="https://www.deepmind.com/">Google Deepmind</a> and an Affiliate Faculty Member of <a href="https://mila.quebec/en/">(Mila)</a>. I earned my Ph.D. in Computer Science from <a href="http://rl.cs.mcgill.ca/">Reasoning and Learning Lab</a> at <a href="https://www.cs.mcgill.ca/">McGill University</a> and <a href="https://mila.quebec/en/">Mila</a>, where I was advised by <a href="https://www.cifar.ca/bio/doina-precup-ai">Doina Precup</a>. I am broadly interested in artificial intelligence and reinforcement learning.

                <p> <b>Research Summary:</b> I am interested in the capability of AI agents to understand and develop broadly intelligent behavior. My research focuses on how agents can efficiently represent the world's knowledge, plan with it, and adapt to changes over time through learning and interaction. See my <a href="https://kkhetarpal.github.io/#research">research</a> page for more details.</p>
              <p>

              </p>
              </p>
              <p style="text-align:center">
                <a href="mailto:khimyakhetarpal@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Khimya Khetarpal CV Long_May2022.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/kkhetarpal">GitHub</a> &nbsp/&nbsp
                <a href="https://scholar.google.ca/citations?hl=en&user=VLOUhF0AAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/khimya">Twitter</a> &nbsp/&nbsp
                <a href="https://www.youtube.com/channel/UCamg7UinZbKhlAwzhR4r7ow?view_as=subscriber">YouTube</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/KhimyaKhetarpal.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/KhimyaKhetarpal_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>


        <!-- The Timeline -->
        <ul class="timeline">

            <li>
                <div class="direction-l">
                    <div class="flag-wrapper">
                        <span class="flag">DeepMind</span>
                        <span class="time-wrapper"><span class="time">December 2022 - Now </span></span>
                    </div>
                    <div class="desc">Research Scientist <small style="color: rgb(250,80,80)"></small></div>
                </div>
            </li>
                            
             <!-- Item Y -->
            <li>
                <div class="direction-r">
                    <div class="flag-wrapper">
                        <span class="flag">Microsoft Research</span>
                        <span class="time-wrapper"><span class="time">Fall 2021, Winter 2022</span></span>
                    </div>
                    <div class="desc">Research Intern <small style="color: rgb(250,80,80)">[Host: Katja Hofmann, Harm van Seijen]</small></div>
                </div>
            </li>
                                                                                                    
            <!-- Item X -->
            <li>
                <div class="direction-l">
                    <div class="flag-wrapper">
                        <span class="flag">DeepMind</span>
                        <span class="time-wrapper"><span class="time">Summer 2021</span></span>
                    </div>
                    <div class="desc">Research Scientist Intern<small style="color: rgb(250,80,80)"> [Host: Satinder Singh, Tom Zahavy]</small></div>
                </div>
            </li>

            <!-- Item 1 -->
            <li>
                <div class="direction-r">
                    <div class="flag-wrapper">
                        <span class="flag">DeepMind</span>
                        <span class="time-wrapper"><span class="time">Fall 2019</span></span>
                    </div>
                    <div class="desc">Research Scientist Intern <small style="color: rgb(250,80,80)">[Host: Doina Precup]</small></div>
                </div>
            </li>

            <!-- Item 2 -->
            <li>
                <div class="direction-l">
                    <div class="flag-wrapper">
                        <span class="flag">McGill University</span>
                        <span class="time-wrapper"><span class="time">2017 - Now</span></span>
                    </div>
                    <div class="desc">Ph.D. in Computer Science</div>
                </div>
            </li>

            <!-- Item 3 -->
            <li>
                <div class="direction-r">
                    <div class="flag-wrapper">
                        <span class="flag">Intel</span>
                        <span class="time-wrapper"><span class="time">2016 - 2017</span></span>
                    </div>
                    <div class="desc">Perceptual Computing Engineer</div>
                </div>
            </li>

            <!-- Item 4 -->
            <li>
                <div class="direction-l">
                    <div class="flag-wrapper">
                        <span class="flag">Univerity of Florida</span>
                        <span class="time-wrapper"><span class="time">2014 - 2016</span></span>
                    </div>
                    <div class="desc">Masters in Computer Engineering</div>
                </div>
            </li>

            <!-- Item 5 -->
            <li>
                <div class="direction-r">
                    <div class="flag-wrapper">
                        <span class="flag">IIT Kanpur</span>
                        <span class="time-wrapper"><span class="time">2013 - 2014</span></span>
                    </div>
                    <div class="desc">Research Associate</div>
                </div>
            </li>

            <!-- Item 5 -->
            <li>
                <div class="direction-l">
                    <div class="flag-wrapper">
                        <span class="flag">Robert Bosch</span>
                        <span class="time-wrapper"><span class="time">2011-2012</span></span>
                    </div>
                    <div class="desc">Embedded Software Development</div>
                </div>
            </li>

            <!-- Item 6 -->
            <li>
                <div class="direction-r">
                    <div class="flag-wrapper">
                        <span class="flag">VIT University</span>
                        <span class="time-wrapper"><span class="time">2007 - 2011</span></span>
                    </div>
                    <div class="desc">B.Tech in Electronics & Communication Engineering</div>
                </div>
            </li>

        </ul>



        <br>
        <br>
        <br>
        <!-- The News -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>  Highlights <small>and</small> News </heading>
              <div class="container sidebar col-md-3">
            <div class="panel-group">
              <div class="panel panel-default">
                <div class="panel-heading">
                  <h4 class="panel-title"></h4>
                </div>
                <div class="panel-body" id="oScroll" >
                <div id="scroll">
                <li><b>26/04/2025</b> Invited Talk on <a href='https://x.com/CoLLAs_Conf/status/1952784436078010565'>Navigating the Affordance Landscape for Continual Agent Adaptation</a> for <a href='https://lifelong-ml.cc/Conferences/2025/program/mainday1#:~:text=Navigating%20the-,Affordance,-Landscape%20for%20Continual'>CoLLAs Early-Career Spotlight Program</a>.</li>
                <p></p>

                <li><b>26/04/2025</b> New blog post on <a href='https://virtual.aistats.org/Conferences/2025/BlogPost_1'>New in ML: A Guide for Navigating the ML Conference Scene</a>.</li>
                <p></p>
                    
                <li><b>21/04/2025</b> New <a href='https://www.corl.org/>CoRL</a> paper <a href='https://arxiv.org/abs/2504.13149'>Long Range Navigator (LRN): Extending robot planning horizons beyond metric maps</a> presents a method that extends planning horizon using an affordance representation mapping camera images to `affordable' frontiers, and optimizing for goal alignment.</li>
                <p></p>

                    
                <li><b>21/01/2025</b> <a href='https://openreview.net/forum?id=8ECfBsjJKZ'>Cracking the Code of Action: A Generative Approach to Affordances for Reinforcement Learning</a> to appear at <i><a href='https://dl4c.github.io/'>ICLR Third Workshop on Deep Learning for Code</a></i>.</li>
                <p></p>
                    
                
                <li><b>21/01/2025</b> <a href='https://arxiv.org/abs/2406.02035'>A Unifying Framework for Action-Conditional Self-Predictive Reinforcement Learning</a> to appear at AISTATS <i><a href='https://aistats.org/aistats2025/index.html'>International Conference on Artificial Intelligence and Statistics (AISTATS)</a></i>.</li>
                <p></p>
                    
                
                <li><b>1/11/2024</b> <a href='https://arxiv.org/abs/2406.02035'>A Unifying Framework for Action-Conditional Self-Predictive Reinforcement Learning</a> to be presented as an Oral at <i><a href='https://neurips.cc/'>NeurIPS 2024 Workshop: Self-Supervised Learning - Theory and Practice</a></i>.</li>
                <p></p>
                    
                
                <li><b>26/09/2024</b> Two papers to appear at <i><a href='https://neurips.cc/'>NeurIPS 2024</a></i>. Details coming soon.</li>
                <p></p>
                    

                <li><b>1/09/2024</b> Attending the <i><a href='https://www.dagstuhl.de/en/seminars/seminar-calendar/seminar-details/24372'>Dagstuhl Seminar on Explainable AI for Sequential Decision Making</a></i>.</li>
                <p></p>   

            
                <li><b>04/25/2024</b> Our work on <i><a href='https://arxiv.org/abs/2402.18762'>Disentangling the Causes of Plasticity Loss in Neural Networks</a></i> is accepted at <i><a href='https://lifelong-ml.cc/'>Conference on Lifelong Learning Agents - CoLLAs 2024</a></i>. See my <a href='https://docs.google.com/presentation/d/1hE_dX_pHi1EiqaVLUfmwZDlA4OBNEfxNwkFXVZ6A5o4/edit?usp=sharing&resourcekey=0-jd4_lmCMHvnF9d982smFsA'>talk slides.</a></li>
                <p></p>
                                                                                                                                                                                                                                                                                                    
                    
                    
                <li><b>12/16/2023</b> Contributed Talk on <i><a href='https://aair-lab.github.io/genplan23/slides/khimya_khetarpal_genplan23.pdf'>"POMRL"</a></i> at <i><a href='https://aair-lab.github.io/genplan23/index.html#'>"NeurIPS Generalization in Planning Workshop"</a></i>.</li>
                <p></p>

                    
                <li><b>11/3/2023</b> Invited Talk at <i><a href='https://robotics.cs.washington.edu/colloquium/'>"UW Robotics Colloqium"</a></i> hosted by Abhishek Gupta and Josh Smith at University of Washington.</li>
                <p></p>

                    
                <li><b>9/30/2023</b> 2 papers to appear in the <i><a href='https://aair-lab.github.io/genplan23/'>"NeurIPS 2023 GenPlan Workshop"</a></i>. </li>
                <p></p>

                    
                <li><b>7/25/2023</b> Our work on <i><a href='https://openreview.net/forum?id=WtXN9bQqWl'>"Discovering Object-Centric Generalized Value Functions From Pixels"</a></i> published at <a href="https://icml.cc/virtual/2023/poster/24264"> ICML 2023</a>. </li>
                <p></p> 

                    
                <li><b>7/18/2023</b> <i><a href='https://openreview.net/forum?id=brGgOAXYtr&referrer=%5BTMLR%5D(%2Fgroup%3Fid%3DTMLR)'>"POMRL: No-Regret Learning-to-Plan with Increasing Horizons"</a></i> published at the Journal of Transactions of Machine Learning Research <a href="https://jmlr.org/tmlr/papers/#:~:text=Expert%20The%20Expert%20Reviewer%20Certificate,broadly%20significant%20for%20the%20field.">(TMLR) </a>. </li>
                <p></p> 


                <li><b>6/30/2023</b> Recognized as an <i>Expert Reviewer</i> at <a href='https://www.jmlr.org/tmlr/expert-reviewers.html'>"Transactions on Machine Learning Research"</a> journal. </li>
                <p></p>    

                    
                <li><b>5/23/2023</b> Invited talk at <a href='https://www.upperbound.ai/'>"Upper Bound, 2023"</a>; AI Week in Edmonton hosted by Amii.</li>
                <p></p>
                    

                <li><b>5/12/2022</b> Started working as a Research Scientist at Google, Deepmind. </li>
                <p></p>    

                    
                <li><b>4/10/2022</b> Successfully defended my PhD dissertation &#127881; </li>
                <p></p>


                <li><b>15/09/2022</b> <i><a href='https://arxiv.org/abs/2012.13490'>"Towards continual reinforcement learning: A review and perspectives"</a></i> accepted for publication at the Journal of Artificial Intelligence Research <a href="https://www.jair.org/index.php/jair">(JAIR) </a>.</li>
                <p></p>


                <li><b>1/09/2022</b> I am co-organizing a <a href="https://neurips.cc/virtual/2022/events/workshop">NeurIPS 2022</a> workshop on <a href="https://attention-learning-workshop.github.io/"> All Things Attention: Bridging Different Perspectives on Attention</a>. Consider submitting your work.</li>
                <p></p>


                <li><b>24/01/2022</b> I am interning with <a href="https://www.microsoft.com/en-us/research/people/havansei/"> Harm van Seijen</a> at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-montreal/">Microsoft Research, Montreal</a> in joint collaboration with <a href="https://www.momen-nejad.org/"> Ida Momennejad</a>, <a href="https://www.microsoft.com/en-us/research/people/sadevlin/"> Sam Devlin</a>, and <a href="https://www.microsoft.com/en-us/research/people/kahofman/"> Katja Hofmann</a> .</li>
                <p></p>
                                
                                
                                
                <p></p>             
                <li><b>28/09/2021</b> <i><a href='https://arxiv.org/pdf/2108.03213.pdf'>"Temporally Abstract Partial Models"</a></i> accepted to <i><a href='https://nips.cc/'>NeurIPS, 2021</a></i>.</li>
                <p></p>



                <p></p>                
                <li><b>20/08/2021</b> I will be interning with <a href="https://www.microsoft.com/en-us/research/people/kahofman/"> Katja Hoffman</a> at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-cambridge/">Microsoft Research, Cambridge</a> starting Nov 2021.</li>
                <p></p>



                <p></p>
                <li><b>20/05/2021</b> I will be interning with <a href="https://web.eecs.umich.edu/~baveja/"> Satinder Singh</a> & <a href="https://tomzahavy.wixsite.com/zahavy"> Tom Zahavy</a> at <a href="https://deepmind.com/"> Deepmind</a> in London starting June 2021.</li>
                <p></p>



                <p></p>
                <li><b>23/2/2021</b> I am co-organizing two <a href="https://iclr.cc/">ICRL 2021</a> workshops on <a href="https://sites.google.com/view/neverendingrl"> A Roadmap to Never-ending Reinforcement Learning</a> & <a href="https://rethinkingmlpapers.github.io/"> Rethinking ML Papers</a>. Consider submitting your work.</li>
                <p></p>



                <p></p>
                <li><b>15/2/2021</b> Invited talk on "Towards Continual Reinforcement Learning: A Review and Perspectives" at <a href="https://www.riken.jp/en/research/labs/aip/generic_tech/approx_bayes_infer/index.html"> RIKEN</a> Center for Advanced Intelligence Project- Approximate Bayesian Inference Team, Japan. </li>
                <p></p>



                <p></p>
                <li><b>12/1/2021</b>  "Learning Robust State Abstractions for Hidden-Parameter Block MDPs" accepted to <i><a href='https://iclr.cc/'>ICLR, 2021</a></i>. </li>
                <p></p>



                <p></p>
                <li><b>2/12/2020</b>  "Self-Supervised Attention-Aware Reinforcement Learning" accepted to <i><a href='https://aaai.org/Conferences/AAAI-21/aaai21call/'>AAAI, 2021</a></i>. Also to appear at <i><a href='https://wensun.github.io/rl_theory_workshop_2020_ICML.github.io'>NeurIPS Workshop on Object Representations for Learning and Reasoning</a></i>. Congrats to my fabulous mentee <a href="https://www.linkedin.com/in/haiping-wu/">Haiping Wu.</li>
                <p></p>



                <p></p>
                  <li><b>2/12/2020</b>  "Variance Penalized On-Policy and Off-Policy Actor-Critic" accepted to <i><a href='https://aaai.org/Conferences/AAAI-21/aaai21call/'>AAAI, 2021</a></i>.
                <p></p>


                <p></p>
                  <li><b>13/11/2020</b>  Invited talk at Northeast Reinforcement Learning and Decision Making Symposium <i><a href='https://all.cs.umass.edu/nerds2020'>(NERDS)</a></i>.</li>
                <p></p>


                <p></p>
                <li><b>8/9/2020</b>  Invited to participate in the <i><a href='https://eecs.berkeley.edu/rising-stars-2020'>Rising Stars 2020</a></i> EECS workshop. Check out my participant profile <i><a href='https://www2.eecs.berkeley.edu/risingstars/2020/participants/khetarpal.shtml'>here</a></i>. An Academic Career Workshop for Women, hosted virtually at UC Berkeley.</li>
                <p></p>


                <p></p>
                <li><b>17/7/2020</b>  Our research on "What can I do here? A Theory of Affordances in RL" is featured in the <i><a href='https://www.technologyreview.com/2020/07/17/1005415/a-concept-in-psychology-is-helping-ai-to-better-navigate-our-world/'>MIT Technology Review</a></i>. </li>
                <p></p>


                <p></p>
                <li><b>2/7/2020</b>  I am thrilled to serve on the Editorial Board for our new <i><a href='https://mila.quebec/en/blog/?cat_id=405//'>Mila Blog</a></i>. Check it out!</li>
                <p></p>


                <p></p>
                <li><b>1/6/2020</b>  Our paper on "What can I do here? A Theory of Affordances in RL" has been accepted at the <i><a href='https://icml.cc/'>International Conference on Machine Learning (ICML) 2020</a></i>. See full paper <i><a href='https://arxiv.org/pdf/2006.15085.pdf'>here.</a></i> </li>
                <p></p>


                <p></p>
                <li><b>14/5/2020</b>  I gave a talk on "A Theory of Affordances in RL" at the  <i><a href='http://incompleteideas.net/rlai.cs.ualberta.ca/RLAI/ualberta.html'>Reinforcement Learning and Artificial Intelligence</a></i> lab meeting at University of Alberta, invited by <i><a href='https://webdocs.cs.ualberta.ca/~whitem/'>Martha White.</a></i>
                </li>
                <p></p>


                <p></p>
                <li><b>6/1/2020</b>  Our work on <i><a href='https://david-abel.github.io/papers/spirl_vpsa.pdf'>Value Preserving State Action Abstractions</a></i> has been accepted for presentation at <a href='https://www.aistats.org/'>AISTATS, 2020.</a>
                </li>
                <p></p>


                <p></p>
                <li><b>11/10/2019</b>  Our work on <i>Options of Interest: Temporal Abstraction with Interest Functions</i> has been accepted at <a href='https://aaai.org/Conferences/AAAI-20/'>AAAI, 2020.</a> A preliminary draft of the ideas in this work was published in the <a href='https://www.aaai.org/ojs/index.php/AAAI/article/view/5114/4987'>AAAI, 2019 Student Abstract proceedings</a>
                </li>
                <p></p>


                <p></p>
                <li><b>13/9/2019</b>   I taught an invited lecture on “Introduction to RL” at the <a href='https://ivado.ca/en/trainings/schools/deep-learning-school-4th-and-5th-edition/#About'>MILA/IVADO summer school on Deep Learning, Montreal, 2019</a>
                </li>
                <p></p>


                <p></p>
                <li><b>29/7/2019</b> I am currently a PhD Research Intern at <a href='https://deepmind.com/'>DeepMind</a> , Montreal working with Doina Precup and the HRL team.
                </li>
                <p></p>


                <p></p>
                <li><b>6/6/2019</b> I am co-organizing a <a href='https://sites.google.com/view/llarla/home'> Lifelong Learning: A Reinforcement Learning (LLARLA) Workshop </a> to be held during <a href='http://rldm.org/workshops-new/'>RLDM, 2019 </a>.
                </li>
                <p></p>


                <p></p>
                <li><b>24/3/2019</b> I am co-organizing a <a href='https://sites.google.com/view/mtlrl/home'> Workshop on Multi-Task and Lifelong Reinforcement Learning </a> to be held during <a href='https://icml.cc/Conferences/2019'>ICML-19 in Long Beach, USA </a>. We have an exicting line up of speakers. Consider submitting your work.
                </li>
                <p></p>


                <p></p>
                <li><b>10/26/2018</b> Our work on <i>Learning Options with Interest Functions</i>, has been selected for poster presentation in the <a href='https://aaai.org/Conferences/AAAI-19/aaai19studentcall/'>AAAI-19 Student Abstract and Poster Program </a> to be held during <a href='https://aaai.org/Conferences/AAAI-19/'>AAAI-19 in Honolulu, Hawaii </a>
                </li>
                <p></p>


                <p></p>
                <li><b>10/15/2018</b>  I have been chosen to be a presenter at the 24th <a href='https://aaai.org/Conferences/AAAI-19/aaai19dccall/'>AAAI/SIGAI Doctoral Consortium (DC) </a> at <a href='https://aaai.org/Conferences/AAAI-19/'>AAAI-19 in Honolulu, Hawaii </a>
                </li>
                <p></p>

                <p></p>
                <li><b>6/20/2018</b> Our work on 'Safe Option-Critic: Learning Safety in the Option-Critic Architecture' Accepted in <a href='http://ala2018.it.nuigalway.ie/'>ICML 2018 Workshop on Adaptive Learning Agents</a>. Paper is now on <a href='https://arxiv.org/abs/1807.08060'>arxiv!</a>
                </li>
                <p></p>


                <p></p>
                <li><b>6/16/2018</b> Our work on 'Attend Before you Act: Leveraging human visual attention for continual learning' Accepted in <a href='https://sites.google.com/view/llarla2018/home?authuser=0'>ICML 2018 Workshop on LifeLong Learning</a>. Paper coming out soon!
                </li>
                <p></p>

                <p></p>
                <li><b>5/13/2018</b> I will be one of the Teaching Assistants at the <a href='https://www.aiforsocialgood.ca/'>AI For Social Good Summer School </a> from May 14-June 21. Super excited to be a part of this initiative.
                </li>
                <p></p>


                <p></p>
                <li><b>2/28/2018</b> Invited talk on Introduction to Computer Vision &amp; Reinforcement Learning at ITTT (Informative Talks on Technical Topics) organized by the <a href='http://www.sb-ieee.ece.mcgill.ca/eventsPast.html'>McGill IEEE Student Branch.</a>
                </li>
                <p></p>


                <p></p>
                <li><b>11/13/2017</b> Volunteered as a mentor at the  <a href='https://www.facebook.com/pg/mcgillinnovation/photos/?tab=album&amp;album_id=1693127260737278'>Women in Innovation and Artificial Intelligence Breakfast</a> organized as the kick-off event of the McGill Innovation Week in the Fall of 2017.
                </li>
                <p></p>


                <p></p>
                <li><b>10/1/2017</b> Organized the weekly <a href='https://github.com/kkhetarpal/ais'>Fall-17 AI Safety RL Lab Reading Group</a> to get started with discussions and initial reading on related literature.
                </li>
                <p></p>


                <p></p>
                <li><b>9/15/2017</b> Joined the Reasoning and Learning lab at McGill University as a 1st year Ph.D. student. Attended the <a href='https://twitter.com/khimya/status/926585771875819521'>ACM Canadian Women Celebration of Women in Computing</a>
                </li>
                <p></p>


                <p></p>
                <li><b>6/1/2017</b> Left job at Intel. I will be joining Ph.D. in CS program at the <a href='http://www.cs.mcgill.ca/academic/graduate/phd'>McGill University</a> in Fall 2017.
                </li>
                <p></p>


                <p></p>
                <li><b>5/1/2017</b> My application for <a href='https://mila.umontreal.ca/en/cours/deep-learning-summer-school-2017/'>Reinforcement Learning Summer School (RLSS) 2017</a>  has been accepted. 225 out of 1130 applicants were selected.
                </li>
                <p></p>

                <p></p>
                <li><b>4/14/2017</b> My application for <a href='http://iplab.dmi.unict.it/icvss2017/'>International Computer Vision Summer School (ICVSS) 2017</a>  has been accepted. 150 out of 430 applicants were selected.</li>
                <p></p>


                <p></p>
                <li><b>03/27/2017</b> Manuscript entitled <a href='http://jainlab.cise.ufl.edu/comics.html#creating-segments-and'>“Creating Segments and Effects on Comics by Clustering Gaze Data”</a> has been accepted for publication in the Transactions on Multimedia Computing Communications and Applications <a href='http://tomm.acm.org/'>[ACM TOMM]</a>
                </li>
                <p></p>


                <p></p>
                <li><b>02/27/2017</b> Invited Talk on <a href='https://kkhetarpal.files.wordpress.com/2016/11/learningvisualrepresentations.pdf'>Learning Visual Representations</a> at the  <a href='https://yezhouyang.engineering.asu.edu/asu-apg-seminar/'>ASU Active Perception Group Seminar Series</a> at the Arizona State University, Tempe.
                </li>
                <p></p>


                <p></p>
                <li><b>08/03/2016</b> Invited Talk at the  <a href='https://www.facebook.com/events/646599912174028/'>Women in Deep Learning</a>  event at the Deep Learning Summer School, Montreal
                </li>
                <p></p>


                <p></p>
                <li><b>06/09/2016</b> As of June-27-2016, I start working as a Software Engineer in the Perception Computing Group-IOTG at Intel Corporation, Arizona. </li>
                <p></p>
                <li><b>05/11/2016</b> My application for <a href='https://sites.google.com/site/deeplearningsummerschool2016/'>CIFAR-CRM 2016 Deep Learning Summer School</a>  has been accepted.
                </li>
                <p></p>


                <p></p>
                <li><b>04/22/2016</b> Paper on 'A Preliminary Benchmark of Four Saliency Algorithms On Comic Art' Accepted in <a href='http://www.mm-artwork.org//'>ICME-MMArt Workshop 2016</a> .
                </li>
                <p></p>


                <p></p>
                <li><b>09/23/2015</b> Attended  <a href='http://www.google.com'>RoboBusiness Expo 2015</a>  at San Jose from Intel.
                </li>
                <p></p>


                <p></p>
                <li><b>02/05/2015</b> I will be spending Summer &amp; Fall of 2015 as a Perception Computing Software Intern at Intel.
                </li>
                <p></p>


                <p></p>
                <li><b>12/10/2014</b> My robot AUMORO built in the course IMDL- Fall 2014 was covered in the <a href='http://www.wuft.org/news/2014/12/10/uf-engineers-display-intelligent-machines-at-robot-demo-day/#3'>WUFT news</a> on Robot Demo Day .
                </li>
                <p></p>

              </div>
            </div>
          </div>

            </td>
          </tr>
        </tbody></table>


        <br>
        <br>
        <br>


         <!-- The Media -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <a name="media"></a>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Media</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" cellspacing="0" cellpadding="10">
          <tr>
            <td width="33%" valign="center" align="center"><a href="https://www.technologyreview.com/2020/07/17/1005415/a-concept-in-psychology-is-helping-ai-to-better-navigate-our-world/"><img src="images/MITTR.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://www.technologyreview.com/2020/07/17/1005415/a-concept-in-psychology-is-helping-ai-to-better-navigate-our-world/" id="mittr">
              <heading>A concept in psychology is helping AI to better navigate our world</heading></a><br>
              <br/>
              <p> <a href="https://www.technologyreview.com/2020/07/17/1005415/a-concept-in-psychology-is-helping-ai-to-better-navigate-our-world/">MIT Technology Review</a> , Hao, K. (July, 2020)
              </p>

            </div>
            </td>
          </tr>
         </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" cellspacing="0" cellpadding="10">
          <tr>
            <td width="33%" valign="center" align="center"><a href="https://www.gainesville.com/picture-gallery/news/local/2014/12/10/uf-robotics-demo/836002007/image/57154649007/#slide:57154649007"><img src="images/aumoro.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://www.wuft.org/news/2014/12/10/uf-engineers-display-intelligent-machines-at-robot-demo-day/#3" id="aumoro">
              <heading>UF Engineers Display Intelligent Machines At Robot Demo Day</heading></a><br>
              <br/>
              <p> <a href="https://www.wuft.org/news/2014/12/10/uf-engineers-display-intelligent-machines-at-robot-demo-day/#3">WUFT News</a> , Whitson, C. (December, 2014)
              </p>
              <p> <a href="https://www.gainesville.com/picture-gallery/news/local/2014/12/10/uf-robotics-demo/836002007/">The Gainesville Sun</a> , Finger, D. (December, 2014)
              </p>

            </div>
            </td>
          </tr>
         </table>




        <!-- The Research -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"  cellspacing="0" cellpadding="10"><tbody>
          <a name="research"></a>
          <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <p> My research aims to (1) understand intelligent behavior that bridges both action and perception grounded in theoretical foundations of reinforcement learning, and (2)
            build AI agents to efficiently represent the world knowledge, plan with it, and adapt to changes over time through learning and interaction. I approach this with the following research directions:
        </p>

        <table style="width:84%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:"0";" cellspacing="0" cellpadding="10">
          <tr bgcolor="FBF7F6">
            <td width="67%" valign="top">
              <p>
              <heading>Selective Attention for Fast Adaptation and Robustness</heading><br>
              <p> Humans adapt robustly in complex and dynamic environments by using selective attention, which is then aggregated in a representation. How can do we enable more efficient learning of such representations to guide behavior?</p>
              <b>Papers</b> <br>
                <a href="https://arxiv.org/abs/1807.09664">Attend Before You Act: Leveraging human visual attention for Continual Learning</a> [ICML Workshop 2018] <br>
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5871">Options of Interest: Temporal abstraction with interest functions</a> [AAAI 2020] <br>
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17235">Self-Supervised Attention-Aware Reinforcement Learning</a> [AAAI 2021] <br>
                </p>

            <div class="paper" id="selectiveattention">

            </div>
            </td>
          </tr>

          <td bgcolor="#FFFFFF" style="line-height:1px;" colspan=3>&nbsp;</td>

          <tr bgcolor="FBF7F6">
            <td width="33%" valign="top">
              <p>
              <heading> Learning Abstractions and Affordances </heading><br>
              <p> Interactive behavior requires dynamically tracking and updating action possibilities, i.e. ``affordances'' (defined as set of state and actions that achieve desired consequences). How can AI agents learn to represent and reason about their environment through this lens?</p>
              <b>Papers</b> <br>
                <a href="https://proceedings.mlr.press/v119/khetarpal20a.html">What can I do here? A theory of Affordances in Reinforcement Learning</a> [ICML 2020] <br>
                <a href="https://proceedings.neurips.cc/paper/2021/hash/0f3d014eead934bbdbacb62a01dc4831-Abstract.html">Temporally Abstract Partial Models </a> [NeurIPS 2021] <br>
                <a href="https://openreview.net/forum?id=WfsYwoltD2">The Paradox of Choice: On the Role of Attention in HRL </a> [NeurIPS Workshop, 2022] <br>
                <a href="https://arxiv.org/pdf/2402.03575.pdf"> Toward Human-AI Alignment in Large-Scale Multi-Player Games </a> [Preprint, 2024] <br>


                </p>

            <div class="paper" id="affordances">

            </div>
            </td>
          </tr>

          <td bgcolor="#FFFFFF" style="line-height:1px;" colspan=3>&nbsp;</td>

          <tr bgcolor="FBF7F6">
            <td width="67%" valign="top">
              <p>
              <heading>Discovery and Continual Reinforcement Learning</heading><br>
              <p> For practical applications, to what extent can RL agents transfer what was learned from previous experience to new situations on-the-fly and adapt to non-stationarity, with the ability to discover more complex capabilities on top of those already developed?</p>
              <b>Papers</b> <br>
                <a href="https://arxiv.org/abs/2012.13490">Continual Reinforcement Learning: A Review and Perspectives </a> [JAIR 2022] <br>
                <a href="https://arxiv.org/abs/2212.14530">POMRL: No-Regret Learning-to-Plan with Increasing Horizons</a> [TMLR 2023] <br>
                <a href="https://icml.cc/virtual/2023/poster/24264">Discovering Object-Centric Generalized Value Functions From Pixels</a> [ICML 2023] <br>
              </p>

            <div class="paper" id="crl">

            </div>
            </td>
          </tr>

        </table>


        <!-- Papers -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"  cellspacing="0" cellpadding="10"><tbody>
          <a name="papers"></a>
          <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>Papers</heading>
            </td>
          </tr>
        </tbody></table>


        <p> Representative papers are <span class="highlight">highlighted</span>.</p> For a complete list, please see <a href="https://scholar.google.ca/citations?hl=en&user=VLOUhF0AAAAJ&view_op=list_works&sortby=pubdate">Google Scholar.</a> &nbsp/&nbsp 

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" cellspacing="0" cellpadding="10">

          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/abs/2504.13149"><img src="images/byolgamma.mp4" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/abs/2504.13149" id="byolgamma">
              <heading>Self-Predictive Representations for Combinatorial Generalization in Behavioral Cloning</heading></a><br>
              Daniel Lawson*, Adriana Hugessen*, Charlotte Cloutier, Glen Berseth+, <b>Khimya Khetarpal+</b><br>
              Workshop on Reinforcement Learning Beyond Rewards: Ingredients for Developing Generalist Agents (<i>RLC</i>) 2025.<br>
              </p>

            <div class="paper" id="lrn">
            <a href="https://arxiv.org/abs/2506.10137">paper</a> |
            <a href="https://self-pred-bc.github.io/">website</a>
            </div>
            </td>
          </tr>

            
          <tr bgcolor="E9F6F5">
            <td width="33%" valign="center" align="center"><a href="https://openreview.net/forum?id=8ECfBsjJKZ"><img src="images/coga.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://openreview.net/forum?id=8ECfBsjJKZ" id="coga">
              <heading>Cracking the Code of Action: A Generative Approach to Affordances for Reinforcement Learning</heading></a><br>
               Lynn Cherif,  Flemming Kondrup,  David Venuto,  Ankit Anand,  Doina Precup,  <b>Khimya Khetarpal</b><br>
               Third Workshop on Deep Learning for Code (<i>ICLR</i>), 2025.<br>
              </p>

            <div class="paper" id="coga">
            <a href="https://openreview.net/forum?id=8ECfBsjJKZ">paper</a>
            </div>
            </td>
          </tr>

          <tr bgcolor="E9F6F5">
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/abs/2504.13149"><img src="images/lrn.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/abs/2504.13149" id="lrn">
              <heading>Long Range Navigator (LRN): Extending robot planning horizons beyond metric maps</heading></a><br>
              Matthew Schmittle, Rohan Baijal, Nathan Hatch, Rosario Scalise, Mateo Guaman Castro, Sidharth Talia, <b>Khimya Khetarpal</b>, Siddhartha Srinivasa, Byron Boots<br>
              Conference on Robot Learning (<i>CoRL</i>) 2025.<br>
              </p>

            <div class="paper" id="lrn">
            <a href="https://arxiv.org/abs/2504.13149">paper</a> |
            <a href="https://personalrobotics.github.io/lrn/">website</a> |
            <a href="https://www.youtube.com/watch?v=BSzeBp26aIU&ab_channel=PersonalRoboticsLab">video</a>
            </div>
            </td>
          </tr>  
            
          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/2406.02035"><img src="images/byolac.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/2406.02035" id="byolac">
              <heading>A Unifying Framework for Action-Conditional Self-Predictive Reinforcement Learning</heading></a><br>
              <b>Khimya Khetarpal*</b>, Zhaohan Daniel Guo*, Bernardo Avila Pires, Yunhao Tang, Clare Lyle, Mark Rowland, Nicolas Heess, Diana Borsa, Arthur Guez, Will Dabney<br>
               Self-Supervised Learning - Theory and Practice Workshop, Neural Information Processing Systems (<i>NeurIPS</i>), 2024. <font color=#FF8080><strong>(Oral)</strong></font><br>
               AISTATS, 2025.
              </p>

            <div class="paper" id="byolac">
            <a href="https://arxiv.org/pdf/2406.02035">paper</a>

            </div>
            </td>
          </tr>

        
          <tr bgcolor="E9F6F5">
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/2402.03575.pdf"><img src="images/humanaialignment.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/2402.03575.pdf" id="humanaialignment">
              <heading>Toward Human-AI Alignment in Large-Scale Multi-Player Games</heading></a><br>
              Sugandha Sharma, Guy Davidson,  <b>Khimya Khetarpal</b>, Anssi Kanervisto, Udit Arora, Katja Hofmann, Ida Momennejad, <br>
              Wordplay: When Language Meets Games @ ACL, Workshop 2024
              </p>

            <div class="paper" id="humanaialignment">
            <a href="https://arxiv.org/abs/2402.03575">paper</a>

            </div>
            </td>
          </tr>

         <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/2402.18762"><img src="images/disentangling.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/2402.18762.pdf" id="plasticity">
              <heading>Disentangling the Causes of Plasticity Loss in Neural Networks</heading></a><br>
              Clare Lyle, Zeyu Zheng, <b>Khimya Khetarpal</b>, Hado van Hasselt, Razvan Pascanu, James Martens, Will Dabney <br>
              Conference on Lifelong Learning Agents (CoLLAs), 2024. 
              </p>

            <div class="paper" id="plasticity">
            <a href="https://arxiv.org/pdf/2402.18762">paper</a> |
            <a href="https://docs.google.com/presentation/d/1hE_dX_pHi1EiqaVLUfmwZDlA4OBNEfxNwkFXVZ6A5o4/edit?usp=sharing&resourcekey=0-jd4_lmCMHvnF9d982smFsA">talk</a>
            
            </div>
            </td>
          </tr>    

            
          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/2310.09997.pdf"><img src="images/forecaster.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/2310.09997.pdf" id="forecaster">
              <heading>Forecaster: Towards Temporally Abstract Tree-Search Planning from Pixels</heading></a><br>
              Thomas Jiralerspong, Flemming Kondrup, Doina Precup, <b>Khimya Khetarpal</b>, <br>
              GenPlan Workshop, Neural Information Processing Systems (<i>NeurIPS</i>), 2023.
              </p>

            <div class="paper" id="forecaster">
            <a href="https://arxiv.org/abs/2310.09997">paper</a>

            </div>
            </td>
          </tr>

            
          <tr>
            <td width="33%" valign="center" align="center"><a href="https://icml.cc/virtual/2023/poster/24264"><img src="images/gvfdiscovery.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="http://proceedings.mlr.press/v202/nath23a/nath23a.pdf" id="gvfs">
              <heading>Discovering Object-Centric Generalized Value Functions From Pixels</heading></a><br>
              Somjit Nath, Gopeshh Subbaraj, <b>Khimya Khetarpal</b>, Samira Ebrahimi Kahou <br>
              International Conference on Machine Learning (<i>ICML</i>), 2023.
              </p>

            <div class="paper" id="gvfs">
            <a href="http://proceedings.mlr.press/v202/nath23a/nath23a.pdf">paper</a>

            </div>
            </td>
          </tr>
            
          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/abs/2212.14530"><img src="images/pomrl.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/abs/2212.14530" id="pomrl">
              <heading>POMRL: No-Regret Learning-to-Plan with Increasing Horizons</heading></a><br>
              <b>Khimya Khetarpal*</b>, Claire Vernade*, Brendan O'Donoghue, Satinder Singh, Tom Zahavy <br>
              Transactions on Machine Learning Research (<i>TMLR</i>), 2023. <font color=#FF8080><strong>(Expert Reviewer Certification.)</strong></font><br>
              GenPlan Workshop, Neural Information Processing Systems (<i>NeurIPS</i>), 2023.    
              </p>

            <div class="paper" id="pomrl">
            <a href="https://arxiv.org/abs/2212.14530">paper</a> |
            <a href='https://aair-lab.github.io/genplan23/slides/khimya_khetarpal_genplan23.pdf'>talk</a> |   
            <a href="https://github.com/kkhetarpal/pomrl">code</a> 

            </div>
            </td>
          </tr>


          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/2201.09653"><img src="images/attentiontypes.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="" id="affordanceshardattention">
              <heading>The Paradox of Choice: Using Attention in Hierarchical Reinforcement Learning</heading></a><br>
              Andrei Nica*, <b>Khimya Khetarpal*</b>, Doina Precup<br>
              All Things Attention Workshop, Neural Information Processing Systems (<i>NeurIPS</i>), 2022.
              </p>

            <div class="paper" id="affordanceshardattention">
            <a href="https://arxiv.org/pdf/2201.09653">paper</a> |
            <a href="https://github.com/andreicnica/hrl_attention">code</a> |

            </div>
            </td>
          </tr>

          <tr bgcolor="E9F6F5">
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/2108.03213.pdf"><img src="images/affordancemodels.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="" id="affordancestheory">
              <heading>Temporally Abstract Partial Models</heading></a><br>
              <b>Khimya Khetarpal</b>, Zafarali Ahmed, Gheorghe Comanici, Doina Precup<br>
              Neural Information Processing Systems (<i>NeurIPS</i>), 2021
              </p>

            <div class="paper" id="tapm">
            <a href="https://arxiv.org/pdf/2108.03213.pdf">paper</a> |
            <a href="https://github.com/deepmind/affordances_option_models">code</a> |
            <a href="https://neurips.cc/virtual/2021/poster/26609">talk</a>

            </div>
            </td>
          </tr>

          <tr >
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/abs/2012.13490"><img src="images/viewsofcrl.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/abs/2012.13490" id="crlsurvey">
              <heading>Towards Continual Reinforcement Learning: A Review and Perspectives</heading></a><br>
              <b>Khimya Khetarpal*</b>, Matthew Riemer*, Irina Rish, Doina Precup<br>
              Journal of Artificial Intelligence Research (<i>JAIR</i>), 2022
              </p>

            <div class="paper" id="crlsurvey">
            <a href="https://arxiv.org/pdf/2012.13490.pdf">paper</a>

            </div>
            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/2007.07206.pdf"><img src="images/hipbmdp.png" alt="sym" width="80%" height="150" style="border-radius:15px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/2007.07206.pdf" id="hipbmdp">
              <heading>Learning Robust State Abstractions for Hidden-Parameter Block MDPs</heading></a><br>
              Amy Zhang, Shagun Sodhani, <b>Khimya Khetarpal</b>, Joelle Pineau<br>
              International Conference on Learning Representations (<i>ICLR</i>), 2021
              </p>

            <div class="paper" id="hipbmdp">
            <a href="https://arxiv.org/pdf/2007.07206.pdf">paper</a> |
            <a href="./data/hipbmdp.bib">bibtex</a> |
            <a href="https://sites.google.com/view/hip-bmdp">webpage</a>
            </div>
            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/2108.01005.pdf"><img src="images/sequoia.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/2108.01005.pdf" id="sequoia">
              <heading>Sequoia: A Software Framework to Unify Continual Learning Research</heading></a><br>
              Fabrice Normandin, Florian Golemo, Oleksiy Ostapenko, Pau Rodriguez, Matthew D Riemer, Julio Hurtado, <b>Khimya Khetarpal</b>, Dominic Zhao, Ryan Lindeborg, Timothée Lesort, Laurent Charlin, Irina Rish, Massimo Caccia<br>
              Workshop on Theory and Foundation of Continual Learning (<i>ICML Workshop</i>), 2021
              </p>

            <div class="paper" id="sequoia">
            <a href="https://arxiv.org/abs/2108.01005">paper</a> |
            <a href="https://github.com/lebrice/Sequoia">framework</a> |
            <a href="https://www.youtube.com/watch?v=0u48vr96zRQ">5 min intro</a>
            </div>
            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><a href=""><img src="images/selfsupervisedrl.png" alt="sym" width="80%" height="150" style="border-radius:15px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://orlrworkshop.github.io/program/orlr_16.html" id="selfsupervisedrl">
              <heading>Self-Supervised Attention-Aware Reinforcement Learning</heading></a><br>
              Haiping Wu, <b>Khimya Khetarpal</b>, Doina Precup <br>
              Association for the Advancement of Artificial Intelligence (<i>AAAI</i>), 2021
              </p>



            <div class="paper" id="selfsupervisedattentionrl">
            <a href="https://orlrworkshop.github.io/index.html">paper</a> |
            <a href="./data/AAAI_2021_Self_supervised_Mask_Poster.pdf">poster</a> |
            <a href="https://orlrworkshop.github.io/index.html">code</a> |
            <a href="https://orlrworkshop.github.io/program/orlr_16.html">talk</a>


            </div>
            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><a href=""><img src="images/vpac.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="" id="vpac">
              <heading>Variance Penalized On-Policy and Off-Policy Actor-Critic</heading></a><br>
              Arushi Jain, Gandharv Patil, Ayush Jain, <b>Khimya Khetarpal</b>, Doina Precup <br>
              Association for the Advancement of Artificial Intelligence (<i>AAAI</i>), 2021
              </p>



            <div class="paper" id="vpac">
            <a href="">paper</a> |
            <a href="./data/AAAI_Poster_Jain_A_10043.pdf">poster</a> |
            <a href="https://github.com/arushi12130/VariancePenalizedActorCritic.git">code</a>


            </div>
            </td>
          </tr>




          <tr bgcolor="E9F6F5">
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/2006.15085.pdf"><img src="images/affordances.gif" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/2006.15085.pdf" id="affordances">
              <heading>What can I do here? A Theory of Affordances in Reinforcement Learning</heading></a> <font color=#FF8080><strong>(Featured in MIT Technology Review)</strong></font><br>
              <b>Khimya Khetarpal</b>, Zafarali Ahmed, Gheorghe Comanici, David Abel, Doina Precup<br>
              International Conference on Machine Learning (<i>ICML</i>), 2020
              </p>

            <div class="paper" id="affordances">
            <a href="https://arxiv.org/pdf/2006.15085.pdf">paper</a> |
            <a href="./data/affordances.bib">bibtex</a> |
            <a href="https://github.com/deepmind/deepmind-research/tree/master/affordances_theory">code</a> |
            <a href="https://www.technologyreview.com/2020/07/17/1005415/a-concept-in-psychology-is-helping-ai-to-better-navigate-our-world/">press</a>
            </div>

            </td>
          </tr>


          <td bgcolor="#FFFFFF" style="line-height:1px;" colspan=3>&nbsp;</td>

          <tr bgcolor="E9F6F5">
            <td width="33%" valign="center" align="center"><a href="https://128.84.21.199/pdf/2001.00271.pdf"><img src="images/ioc.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://128.84.21.199/pdf/2001.00271.pdf" id="interest options">
              <heading>Options of Interest: Temporal Abstraction with Interest Functions</heading></a><br>
              <b>Khimya Khetarpal</b>, Martin Klissarov, Maxime Chevalier-Boisvert, Pierre-Luc Bacon, Doina Precup<br>
              Association for the Advancement of Artificial Intelligence (<i>AAAI</i>), 2020
              </p>


            <div class="paper" id="optionsofinterest">
            <a href="https://128.84.21.199/pdf/2001.00271.pdf">paper</a> |
            <a href="./data/opint.bib">bibtex</a> |
            <a href="https://github.com/kkhetarpal/ioc">code</a> |
            <a href="https://sites.google.com/view/optionsofinterest">webpage</a> |
            <a href="https://kkhetarpal.files.wordpress.com/2019/12/neurips_drl_optionsofinterest_poster.pdf">poster</a>

            </div>
            </td>
          </tr>





          <tr>
            <td width="33%" valign="center" align="center"><a href="https://david-abel.github.io/papers/aistats2020_vpsa-full.pdf"><img src="images/phirelativeoptions.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="http://proceedings.mlr.press/v108/abel20a/abel20a.pdf" id="phirelativeoptions">
              <heading>Value Preserving State-Action Abstractions</heading></a><br>
              David Abel, Nathan Umbanhowar, <b>Khimya Khetarpal</b>, Dilip Arumugam, Doina Precup, and Michael L. Littman<br>
              International Conference on Artificial Intelligence and Statistics (<i>AISTATS</i>), 2020
              </p>



            <div class="paper" id="phirelativeoptions">
            <a href="https://david-abel.github.io/papers/aistats2020_vpsa-full.pdf">paper</a> |
            <a href="./data/phirelativeoptions.bib">bibtex</a> |
            <a href="https://github.com/david-abel/vpsa_aistats2020">code</a>

            </div>
            </td>
          </tr>



          <tr>
            <td width="33%" valign="center" align="center"><a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/5082"><img src="images/aaai_dc.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/5082" id="ioc_dc">
              <heading>Learning Generalized Temporal Abstractions across Both Action and Perception</heading></a> <font color=#FF8080><strong>(Scholarship Award)</strong></font> <br>
              <b>Khimya Khetarpal</b> <br>
              Association for the Advancement of Artificial Intelligence (<i>AAAI</i>), 2019 <br> Doctorial Consortium Track
              </p>


            <div class="paper" id="ioc_dc">
            <a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/5082/4955">paper</a> |
            <a href="./data/aaaidc.bib">bibtex</a>

            </div>
            </td>
          </tr>



          <tr>
            <td width="33%" valign="center" align="center"><a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/5114"><img src="images/task1_HC_OC.gif" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/5114" id="ioc_sa">
              <heading>Learning Options with Interest Functions</heading></a> <font color=#FF8080><strong>(3 Minute Thesis Finalist)</strong></font> <br>
              <b>Khimya Khetarpal</b>, Doina Precup <br>
              Association for the Advancement of Artificial Intelligence (<i>AAAI</i>), 2019 <br> Student Abstract Track
              </p>


            <div class="paper" id="ioc_dc">
            <a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/5114/4987">paper</a> |
            <a href="./data/opint.bib">bibtex</a> |
            <a href="https://github.com/kkhetarpal/ioc">code</a> |
            <a href="https://sites.google.com/view/optionsofinterest">webpage</a> |
            <a href="./data/poster_interestfunctions.pdf">poster</a>

            </div>
            </td>
          </tr>


          <tr>
            <td width="33%" valign="center" align="center"><a href="https://tarl2019.github.io/assets/papers/klissarov2019variational.pdf"><img src="images/vse.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://tarl2019.github.io/assets/papers/klissarov2019variational.pdf" id="vse">
              <heading>Variational State Encoding as Intrinsic Motivation in Reinforcement Learning</heading></a><br>
              Martin Klissarov*, Riashat Islam*, <b>Khimya Khetarpal</b>, Doina Precup <br>
              The Multi-disciplinary Conference on Reinforcement Learning and Decision Making (<i>RLDM</i>), 2019 <br>
              </p>


            <div class="paper" id="vse">
            <a href="https://tarl2019.github.io/assets/papers/klissarov2019variational.pdf">paper</a> |
            <a href="./data/vse.bib">bibtex</a>

            </div>
            </td>
          </tr>


          <tr bgcolor="E9F6F5">
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/1807.09664"><img src="images/mzumagbvs.gif" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/1807.09664.pdf" id="attendbeforeyouact">
              <heading>Attend before you act: Leveraging human visual attention for continual learning</heading></a> <font color=#FF8080><strong>(Best Paper Award- 3rd Place)</strong></font> <br>
              <b>Khimya Khetarpal</b>, Doina Precup<br>
              Lifelong Learning: A Reinforcement Learning Approach Workshop (<i>ICML</i>), 2018
              </p>


            <div class="paper" id="attendbeforeyouact">
            <a href="https://arxiv.org/pdf/1807.09664.pdf">paper</a> |
            <a href="./data/attendbeforeyouact.bib">bibtex</a> |
            <a href="https://github.com/kkhetarpal/unrealwithattention">code</a> |
            <a href="https://sites.google.com/view/attendbeforeyouact">webpage</a> |
            <a href="./data/attendbeforeyouact_llarla_poster.pdf">poster</a>

            </div>
            </td>
          </tr>



          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/1807.08060"><img src="images/soc.png" alt="sym" width="80%" height="150" style="border-radius:15px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/1807.08060.pdf" id="soc">
              <heading>Safe option-critic: Learning safety in the option-critic architecture</heading></a><br>
              Arushi Jain*, <b>Khimya Khetarpal*</b>, Doina Precup<br>
              Adaptive Learning Agents Workshop, (<i>ICML</i>), 2018.<br>
              Invited for submission to special issue of The Knowledge Engineering Review (Cambridge University Press journal)
              </p>


            <div class="paper" id="soc">
            <a href="https://arxiv.org/pdf/1807.08060.pdf">paper</a> |
            <a href="./data/soc.bib">bibtex</a> |
            <a href="https://github.com/kkhetarpal/safe_a2oc_delib">code</a> |
            <a href="https://sites.google.com/view/safe-option-critic">webpage</a>

            </div>
            </td>
          </tr>



          <tr>
            <td width="33%" valign="center" align="center"><a href="https://openreview.net/forum?id=HJgAmITcgm"><img src="images/reevaluate.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://openreview.net/pdf?id=HJgAmITcgm" id="reevaluate">
              <heading>Re-evaluate: Reproducibility in evaluating reinforcement learning algorithms</heading></a><br>
              <b>Khimya Khetarpal*</b>, Zafarali Ahmed*, Andre Cianflone, Riashat Islam, Joelle Pineau<br>
               Reproducibility in Machine Learning Workshop, (<i>ICML</i>), 2018.<br>
              </p>


            <div class="paper" id="reevaluate">
            <a href="https://openreview.net/pdf?id=HJgAmITcgm">paper</a> |
            <a href="./data/reevaluate.bib">bibtex</a> |
            <a href="https://github.com/kkhetarpal/prototype4evaluation">code</a> |
            <a href="./data/ICML_RML_2018_poster.pdf">poster</a>

            </div>
            </td>
          </tr>



          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/1811.10732.pdf"><img src="images/envllarla.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://arxiv.org/pdf/1811.10732.pdf" id="envllarla">
              <heading>Environments for Lifelong Reinforcement Learning</heading></a><br>
              <b>Khimya Khetarpal*</b>, Shagun Sodhani*, Sarath Chandar, Doina Precup<br>
               Continual Learning Workshop, Workshop, (<i>NeurIPS</i>), 2018.<br>
                </p>


            <div class="paper" id="envllarla">
            <a href="https://arxiv.org/pdf/1811.10732.pdf">paper</a> |
            <a href="./data/envllarla.bib">bibtex</a> |
            <a href="./data/poster_lifelonglearningenvironments_cl2018.pdf">poster</a>

            </div>
            </td>
          </tr>


          <tr>
            <td width="33%" valign="center" align="center"><a href="https://dl.acm.org/doi/10.1145/3078836"><img src="images/tommgaze.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://dl.acm.org/doi/10.1145/3078836" id="tommgaze">
              <heading>Creating Segments and Effects on Comics by Clustering Gaze Data</heading></a><br>
              Ishwarya Thirunarayanan, <b>Khimya Khetarpal</b>, Sanjeev Koppal, Olivier Le Meur, John Shea and Eakta Jain<br>
              ACM Transactions on Multimedia Computing, Communications, and Applications, (<i>TOMM</i>), 2017.<br>
              </p>


            <div class="paper" id="tommgaze">
            <a href="https://jainlab.cise.ufl.edu/documents/REQGazeComics_preprint.pdf">paper</a> |
            <a href="./data/tommgaze.bib">bibtex</a> |
            <a href="https://jainlab.cise.ufl.edu/comics.html#creating-segments-and">webpage</a>

            </div>
            </td>
          </tr>


          <tr>
            <td width="33%" valign="center" align="center"><a href="https://ieeexplore.ieee.org/abstract/document/7574728"><img src="images/comicbenchmark.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://ieeexplore.ieee.org/abstract/document/7574728" id="comicbenchmark">
              <heading>A Preliminary Benchmark Of Four Saliency Algorithms On Comic Art</heading></a><br>
              <b>Khimya Khetarpal</b>, Eakta Jain<br>
              International Workshop on Multimedia Artworks Analysis (MMArt), <br>(<i>IEEE ICME</i>), 2016.<br>
              </p>


            <div class="paper" id="comicbenchmark">
            <a href="./data/W201_CameraReadyVersion_compressed.pdf">paper</a> |
            <a href="./data/comicbenchmark.bib">bibtex</a> |
            <a href="https://jainlab.cise.ufl.edu/comics.html">webpage</a> |
            <a href="./data/comicbenchmark.pdf">talk slides</a>

            </div>
            </td>
          </tr>


          <tr>
            <td width="33%" valign="center" align="center"><a href="https://www.sciencedirect.com/science/article/pii/S1474667016327409"><img src="images/moga.gif" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <p><a href="https://www.sciencedirect.com/science/article/pii/S1474667016327409" id="moga">
              <heading>Mobile robot navigation using evolving neural controller in unstructured environments</heading></a><br>
              AwhanPatnaik, <b>Khimya Khetarpal</b>, Laxmidhar Behera<br>
              International Conference on – Advances in Control and Optimization of Dynamical Systems, <br>(<i>IFAC</i>), 2014.<br>
              </p>


            <div class="paper" id="moga">
            <a href="https://www.sciencedirect.com/science/article/pii/S1474667016327409">paper</a> |
            <a href="./data/moga.bib">bibtex</a> |
            <a href="https://github.com/kkhetarpal/moga_mobrob">code</a> |
            <a href="https://youtu.be/x6Xuqw0te7k">video</a> |
            <a href="./data/mobile-robot-navigation-using-evolvinganeural-controller-in-unstructuredc2aenvironments.pdf">talk slides</a>

            </div>
            </td>
          </tr>

        </table>


        <br>
        <br>
        <br>

       <!-- The Talks -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <a name="talks"></a>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Representative Talks</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" cellspacing="0" cellpadding="10">

          <tr>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/KbVZNZOTRWo?si=VaFXfprEqP8Bq1H1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          </tr>

        </table>


    
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <a name="talks"></a>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Talks</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" cellspacing="0" cellpadding="10">


            <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/pdf/2402.18762"><img src="images/disentangling.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://docs.google.com/presentation/d/1hE_dX_pHi1EiqaVLUfmwZDlA4OBNEfxNwkFXVZ6A5o4/edit?usp=sharing&resourcekey=0-jd4_lmCMHvnF9d982smFsA" id="collasoral">
              <heading>Disentangling the Causes of Plasticity Loss in Neural Networks</heading><br>
              <br/>
              <a href="https://lifelong-ml.cc/"> The Conference on Lifelong Learning Agents (CoLLAs), Pisa, Italy</a>, Spotlight Talk,  May, 2024 <br/>
                

            </div>

            </td>
          </tr>

            
            <tr>
            <td width="33%" valign="center" align="center"><a href="https://docs.google.com/presentation/d/1JDmQlIsVYfd5D-zYekB6Bui4D0g4wf7gGXEsdfd5E9A/edit?usp=sharing&resourcekey=0-3b6WnEdVS2TBxHi1Xcsv-A"><img src="images/pomrl_fig.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://docs.google.com/presentation/d/1JDmQlIsVYfd5D-zYekB6Bui4D0g4wf7gGXEsdfd5E9A/edit?usp=sharing&resourcekey=0-3b6WnEdVS2TBxHi1Xcsv-A" id="phddefence">
              <heading>POMRL: No-Regret Learning-to-Plan with Increasing Horizons</heading><br>
              <br/>
              <a href="https://www.upperbound.ai/"> Upper Bound, Amii, Edmonton</a>, Invited Talk,  May, 2023 <br/>
              <a href="https://about.meta.com/"> Meta Paris, Virtual</a>,  Invited Talk, Aug, 2023 <br/>
              <a href="https://weirdlab.cs.washington.edu/"> WEIRD Lab, UW, Seattle</a>,  Invited Talk, Apr, 2023 <br/>
                

            </div>

            </td>
          </tr>

            
            <tr>
            <td width="33%" valign="center" align="center"><a href="https://docs.google.com/presentation/d/1McMkGRlXyCfyfe_Phb1qu6tweVRKq-t3sVwoO_NnDcw/edit?usp=sharing&resourcekey=0-t0IiMSea9pKAYHU9pbkntQ"><img src="images/thesisoverview.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://docs.google.com/presentation/d/1McMkGRlXyCfyfe_Phb1qu6tweVRKq-t3sVwoO_NnDcw/edit?usp=sharing&resourcekey=0-t0IiMSea9pKAYHU9pbkntQ" id="phddefence">
              <heading>Bridging State and Action: Towards Continual Reinforcement Learning</heading></a> <font color=#FF8080><strong>(PhD Defence)</strong></font><br>
              <br/>
              <a href="https://mila.quebec/en/"> RL Lab, McGill University, Mila, Montreal</a>,  October, 2022 <br/>
              <a href="https://docs.google.com/presentation/d/1McMkGRlXyCfyfe_Phb1qu6tweVRKq-t3sVwoO_NnDcw/edit?usp=sharing&resourcekey=0-t0IiMSea9pKAYHU9pbkntQ">slides</a> |
              <a href="https://twitter.com/khimya/status/1578610624711766017?s=20&t=CC87vi5wunHXcVYLsEEDnQ">pictures</a>

            </div>

            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/abs/2108.03213"><img src="images/Bridging_Talk2022_KhimyaKhetarpal.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://arxiv.org/abs/2108.03213" id="tapm">
              <heading>Bridging State and Action: Towards Continual Reinforcement Learning</heading></a><br>
              <br/>
              <a href="http://rlai.ualberta.ca/"> RLAI Lab, University of Alberta, Edmonton</a>,  Invited Talk, 2022 <br/>
              <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-new-york/"> Microsoft Research, NYC</a>,  Invited Talk, 2022 (virtual) <br/>
              <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-montreal/"> Microsoft Research, Montreal</a>,  Invited Talk, 2022 (virtual) <br/>
              <a href="http://robotics.cs.brown.edu/"> Brown Robotics Lab</a>, Brown University,  Invited Talk, 2022, (virtual)  <br/>
              <a href="https://www.deepmind.com/"> Deepmind </a>, Invited Talk, 2022, (virtual)  <br/>
              <a href="https://research.google/"> Google Research </a>, Invited Talk, 2022  (virtual) <br/>


            </div>

            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/abs/2108.03213"><img src="images/tapmsnippet.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://arxiv.org/abs/2108.03213" id="tapm">
              <heading>Temporally Abstract Partial Models</heading></a><br>
              Neural Information Processing Systems (<i>NeurIPS</i>), 2021 <br>
              <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-cambridge/"> Microsoft Research</a> RL Reading Group, Invited Talk, 2021

            <div class="paper" id="tapm">
            <a href="https://arxiv.org/abs/2108.03213">paper</a> |
            <a href="https://github.com/deepmind/affordances_option_models">code</a> |
            <a href="https://docs.google.com/presentation/d/1SdlQossQSFeLQ6Mq1H6A_rE2wW_9-tATTJd4gcKKOb0/edit?usp=sharing">slides</a> |
            <a href="https://neurips.cc/virtual/2021/poster/26609">talk</a>
            </div>

            </td>
          </tr>
                                                                                     
                                                                                     
          <tr>
            <td width="33%" valign="center" align="center"><a href="https://arxiv.org/abs/2012.13490"><img src="images/viewsofcrl.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://icml.cc/virtual/2020/poster/6274" id="crlsurveypaper">
              <heading>Towards Continual Reinforcement Learning: A Review and Perspectives</heading></a><br>
              <a href="https://www.riken.jp/en/research/labs/aip/generic_tech/approx_bayes_infer/index.html"> RIKEN</a> Center for Advanced Intelligence Project- Approximate Bayesian Inference Team (<i>Japan</i>), Invited Talk, 2021

            <div class="paper" id="crlsurveypaper">
            <a href="https://arxiv.org/pdf/2012.13490">paper</a> |
            <a href="https://docs.google.com/presentation/d/1QhE3d5tOiv8pD6hwUb4vbCsVBTado2viEcw74OmZydw/edit?usp=sharing">slides</a> |
            <a href="https://twitter.com/EmtiyazKhan/status/1361322651742953483?s=20">twitter</a>
            </div>

            </td>
          </tr>


          <tr>
            <td width="33%" valign="center" align="center"><a href="https://icml.cc/virtual/2020/poster/6274"><img src="images/affordances.gif" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://icml.cc/virtual/2020/poster/6274" id="affordances_talk">
              <heading>What can I do here? A Theory of Affordances in Reinforcement Learning</heading></a> <font color=#FF8080><strong>(Featured in MIT Technology Review)</strong></font><br>
              International Conference on Machine Learning (<i>ICML</i>), Virtual Vienna, 2020
              Northeast Reinforcement Learning and Decision Making Symposium (<i><a href="https://all.cs.umass.edu/nerds2020">NERDS</a></i>), 2020

            <div class="paper" id="affordances_talk">
            <a href="https://icml.cc/virtual/2020/poster/6274">talk</a> |
            <a href="https://docs.google.com/presentation/d/1dXhNM0idFwCcEzchIhqoh69chGPl8-RQQMJ5MThPGOw/edit?usp=sharing">slides</a> |
            <a href="https://arxiv.org/pdf/2006.15085.pdf">paper</a> |
            <a href="https://twitter.com/DeepMind/status/1279029036333895685?s=20">twitter</a>
            </div>

            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><a href="https://docs.google.com/presentation/d/1a0sNUlQ9WbwwZ4lYEhelkC7wo7VcM9wXr3kFCJSla2s/edit?usp=sharing"><img src="images/aaai_ioc.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://docs.google.com/presentation/d/1a0sNUlQ9WbwwZ4lYEhelkC7wo7VcM9wXr3kFCJSla2s/edit?usp=sharing" id="interest_talk">
              <heading>Options of Interest: Temporal Abstraction with Interest Functions</heading></a><br>
              Association for the Advancement of Artificial Intelligence (<i>AAAI</i>), New York, 2020.


            <div class="paper" id="interest_talk">
            <a href="https://docs.google.com/presentation/d/1a0sNUlQ9WbwwZ4lYEhelkC7wo7VcM9wXr3kFCJSla2s/edit?usp=sharing">AAAI spotlight</a> |
            <a href="./data/OptionsOfInterest_TalkSlides_DM_HRL.pdf">DeepMind HRL Meeting</a> |
            <a href="https://128.84.21.199/pdf/2001.00271.pdf">paper</a> |
            <a href="https://twitter.com/khimya/status/1213236585614974977?s=20">twitter</a>

            </div>
            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/5082"><img src="images/aaai_dc.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/5082" id="ioc_dc">
              <heading>Learning Generalized Temporal Abstractions across Both Action and Perception</heading></a> <br>
              Association for the Advancement of Artificial Intelligence (<i>AAAI</i>), Hawaii, 2019 <br>
              Doctorial Consortium Track, <font color=#FF8080><strong>(Mentor: Michael Littman)</strong></font>


            <div class="paper" id="ioc_dc">
            <a href="./data/aaaidc.pdf">AAAI DC</a> |
            <a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/5082/4955">paper</a> |
            <a href="https://twitter.com/khimya/status/1090042378184941568?s=20">twitter</a>

            </div>
            </td>
          </tr>


          <tr>
            <td width="33%" valign="center" align="center"><a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/5114"><img src="images/3mt.jpg" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/5114" id="ioc_sa">
              <heading>Learning Options with Interest Functions</heading></a><br>
              Association for the Advancement of Artificial Intelligence (<i>AAAI</i>), Hawaii, 2019 <br>
              Student Abstract Track, <font color=#FF8080><strong>(3 Minute Thesis Finalist)</strong></font>


            <div class="paper" id="ioc_dc">
            <a href="./images/3mt.jpg">talk</a> |
            <a href="https://sites.google.com/view/optionsofinterest">webpage</a> |
            <a href="https://twitter.com/khimya/status/1090820146636062720?s=20">twitter</a>

            </div>
            </td>
          </tr>


           <tr>
            <td width="33%" valign="center" align="center"><a href="./data/attendbeforeyouact_icml18.pdf"><img src="images/mzumagbvs.gif" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            </td>
            <td width="67%" valign="top">
              <a href="https://arxiv.org/pdf/1807.09664.pdf" id="attendbeforeyouact">
              <heading>Attend before you act: Leveraging human visual attention for continual learning</heading></a> <font color=#FF8080><strong>(Best Paper Award- 3rd Place)</strong></font> <br>
              Lifelong Learning: A Reinforcement Learning Approach Workshop (<i>ICML</i>), Stockholm, 2018


            <div class="paper" id="attendbeforeyouact">
            <a href="./data/attendbeforeyouact_icml18.pdf">oral</a> |
            <a href="https://sites.google.com/view/attendbeforeyouact">webpage</a> |
            <a href="https://twitter.com/khimya/status/1018256642264190980?s=20">twitter</a>

            </div>
            </td>
          </tr>

         </table>

<!-- Students -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <a name="students"></a>
          <tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Students</heading>
            </td>
          </tr>
           </tbody></table>


          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
<!--            <td width="33%" valign="center" align="center">-->
<!--            <td width="75%" valign="center">-->
              <ul class="students">
                  <item>
                    <img src="images/daniellawson.jpeg" class="rounded" />
                    <a href="https://danielblawson.github.io/" target="_blank">Daniel Lawson</a>
                    <p class="current">PhD</p>
                    co-advised with <a href="https://neo-x.github.io/" target="_blank">Glen Berseth</a>
<!--                    <p class="topics">GenRL</p>-->
                  </item>
                  
                  <item>
                    <img src="images/lynn.jpeg" class="rounded" />
                    <a href="https://lc-dev.github.io/" target="_blank">Lynn Cherif</a>
                    <p class="current">MS</p>
                    co-advised with <a href="https://mila.quebec/en/directory/doina-precup" target="_blank">Doina Precup</a>
<!--                    <p class="topics">TAP</p>-->
                  </item>
                  
                  <item>
                    <img src="images/somjit.jpeg" class="rounded" />
                    <a href="https://somjit77.github.io/" target="_blank">Somjit Nath</a>
                    <p class="current">PhD</p>
<!--                    <p class="topics">GVFs</p>-->
                  </item>

                  <item>
                    <img src="images/thomas.jpeg" class="rounded" />
                    <a href="https://superkaiba.github.io/" target="_blank">Thomas Jiralerspong</a>
                    <p class="current">UG</p>
<!--                    <p class="topics">GVFs</p>-->
                  </item>

                  <item>
                    <img src="images/no-picture.jpg" style="width:90px;height:100;" />
                    <a href="https://www.linkedin.com/in/haiping-wu/" target="_blank">Haiping Wu</a>
                    <p class="current">MS</p>
<!--                    <p class="topics"><a href=""https://ojs.aaai.org/index.php/AAAI/article/view/17235">AAAI (2021)</a></p>-->
                  </item>
<!--             <hr class="rounded">-->
<!--              <a href="https://www.linkedin.com/in/haiping-wu/">Haiping Wu (McGill/Mila, CS Masters)</a>-->
<!--            <p>Work led by Haiping on "Self-Supervised Attention-Aware Reinforcement Learning" accepted to <i><a href='https://aaai.org/Conferences/AAAI-21/aaai21call/'>AAAI, 2021</a></i>. Also to appear at <i><a href='https://orlrworkshop.github.io/index.html'>NeurIPS Workshop on Object Representations for Learning and Reasoning</a></i>. See preliminary draft <i><a href='https://github.com/orlrworkshop/orlrworkshop.github.io/blob/master/pdf/ORLR_16.pdf'>here</a></i>.-->
<!--            </p>-->
<!--              <br>-->
<!--              <br>-->
<!--           </td>-->
<!--          </tr>-->
          </tbody></table>

              
        <!-- The Service -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <a name="service"></a>
          <tr>
              
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="33%" valign="center" align="center"><a href="http://rl.cs.mcgill.ca/courses.html"><img src="images/mcgill_sig_red.png" alt="sym" width="80%" height="120" style="border-radius:1px"></a>
            <td width="75%" valign="center">
              <a href="https://www.cs.mcgill.ca/~dprecup/courses/rl.html">Teaching Assistant, COMP-767 Reinforcement Learning, Winter 2020</a>
              <br>
              <br>
              <a href="https://www.mcgill.ca/study/2018-2019/courses/comp-208">Teaching Assistant, COMP-208 Computers in Engineering, Winter 2018</a>
              <br>
              <br>
              <a href="./data/hrl_lecture.pdf">Guest Lecture, Hierarchical RL, Management Studies, 2019</a>
              <a href="./data/hrl_lecture.pdf">[slides]</a>
            </td>
          </tr>

          <tr>
            <td width="33%" valign="center" align="center"><a href="https://ivado.ca/en/trainings/schools/ivado-mila-deep-learning-school-5th-edition-2/"><img src="images/ivado.png" alt="sym" width="80%" height="100" style="border-radius:1px"></a>
            <td width="75%" valign="center">
              <a href="https://ivado.ca/en/trainings/schools/ivado-mila-deep-learning-school-5th-edition-2/">Reinforcement Learning, IVADO Deep Learning Summer School, 2019</a>
              <a href="https://drive.google.com/file/d/10poTlY1B0n2HkHynzfg4AV7dxQo623hm/view">[slides]</a>
            </td>
          </tr>


          <tr>
            <td width="33%" valign="center" align="center"><a href="https://www.ai4goodlab.com/"><img src="images/ai4good.png" alt="sym" width="80%" height="100" style="border-radius:1px"></a>
            <td width="75%" valign="center">
              <a href="https://www.ai4goodlab.com/montreal-program">Lecturer, Reinforcement Learning, 2020</a>
              <a href="./data/ai4good 2020 rl part 2.pdf">[slides]</a>
              <br>
              <br>
              <a href="https://www.ai4goodlab.com/">Lecturer, Deep Reinforcement Learning, 2019</a>
              <a href="./data/ai4good 2019 rl part 2.pdf">[slides]</a>
              <br>
              <br>
              <a href="https://www.facebook.com/OsmoMTL/posts/1630796146957802">Teaching Assistant, 2018</a>
              <a href="https://github.com/ai4socialgood/Resources-2018">[resources]</a>
            </td>
          </tr>
        </tbody></table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Organizational Roles</heading>
            </td>
          </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="33%" valign="center" align="center"><a href="https://sites.google.com/view/continual-rl"><img src="images/wordcloud_organizing.png" alt="sym" width="80%" height="100" style="border-radius:15px"></a>
            <td width="75%" valign="center">
              <a href"https://rl-conference.cc//">Reinforcement Learning Conference, RLC 2025, Area Chair</a>
              <br>
              <br>
              <a href="https://attention-learning-workshop.github.io/"> All Things Attention: Bridging Different Perspectives on Attention, NeurIPS 2022</a>
              <br>
              <br>
              <a href="https://sites.google.com/view/neverendingrl">A Roadmap to Never-Ending Reinforcement Learning, Workshop, ICLR 2021</a>
              <br>
              <br>
              <a href="https://rethinkingmlpapers.github.io/">Rethinking ML Papers, Workshop, ICLR 2021</a>
              <br>
              <br>
              <a href="https://sites.google.com/view/continual-rl">Continual Reinforcement Learning, Un-Workshop WiML, ICML 2020</a>
              <br>
              <br>
              <a href="https://sites.google.com/view/llarla/home?authuser=0">Lifelong Learning: A Reinforcement Learning Approach (LLARLA), RLDM 2019</a>
              <br>
              <br>
              <a href="https://sites.google.com/view/mtlrl/home">Multi-Task and Lifelong Reinforcement Learning Workshop, ICML 2019</a>

           </td>
          </tr>
          </tbody></table>



         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Reviewing</heading>
            </td>
          </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="33%" valign="center" align="center"><a href="#top"><img src="images/wordcloud_reviewing.png" alt="sym" width="80%" height="150" style="border-radius:1px"></a>
            <td width="75%" valign="center">
              <a href="https://jmlr.org/">Reviewer, JMLR, Journal of Machine Learning Research </a><br><br>
              <a href="https://www.jmlr.org/tmlr/">Reviewer, TMLR, Transactions on Machine Learning Research </a><br><br>
              <a href="https://ewrl.wordpress.com/ewrl15-2022/">Reviewer, EWRL, European Workshop on Reinforcement Learning('22) </a><br><br>
              <a href="https://iclr.cc/virtual_2020/index.html">Reviewer, AISTATS ('21), ICLR ('20, '21), NeurIPS ('20, '21, '22)</a><br><br>
              <a href="https://reproducibility-challenge.github.io/neurips2019/">Reviewer, NeurIPS, Deep RL Workshop ('20), Reproducibility Challenge ('19)</a><br><br>
              <a href="https://sites.google.com/view/continual2018/submissions?authuser=0">Program Committee, Continual Learning Workshop, NeurIPS 2018</a><br><br>
              <a href="https://aiforsocialgood.github.io/2018/organizers.htm">Reviewer, AI for Social Good Workshop, NeurIPS 2018</a>
            </td>
          </tr>
          </tbody></table>
        </tbody></table>








        </tr>






        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                &copy Khimya Khetarpal<br>
                Base Design & CSS courtsey <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>


         </tbody></table>
        </td>
       </tr>
    </table>





</body>

</html>
